{"ast":null,"code":"var _jsxFileName = \"/Users/himanshipatel/Documents/react-trans/src/SpeechToText/index.js\",\n  _s = $RefreshSig$();\nimport React, { useState } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst SpeechToText = () => {\n  _s();\n  const [transcript, setTranscript] = useState('');\n  const startRecording = () => {\n    const recognition = new window.webkitSpeechRecognition();\n    recognition.onresult = event => {\n      const speechToText = event.results[0][0].transcript;\n      setTranscript(speechToText);\n    };\n    recognition.start();\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: startRecording,\n      children: \"Start Listening\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 17,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: startRecording,\n      children: \"Start Listening\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 18,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: transcript\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 19,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 16,\n    columnNumber: 5\n  }, this);\n};\n_s(SpeechToText, \"fYK6laDzkgNdQlXJTHY9pPP5av0=\");\n_c = SpeechToText;\nexport default SpeechToText;\nvar _c;\n$RefreshReg$(_c, \"SpeechToText\");","map":{"version":3,"names":["React","useState","jsxDEV","_jsxDEV","SpeechToText","_s","transcript","setTranscript","startRecording","recognition","window","webkitSpeechRecognition","onresult","event","speechToText","results","start","children","onClick","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/himanshipatel/Documents/react-trans/src/SpeechToText/index.js"],"sourcesContent":["import React, { useState } from 'react';\n\nconst SpeechToText = () => {\n  const [transcript, setTranscript] = useState('');\n  \n  const startRecording = () => {\n    const recognition = new window.webkitSpeechRecognition();\n    recognition.onresult = event => {\n      const speechToText = event.results[0][0].transcript;\n      setTranscript(speechToText);\n    };\n    recognition.start();\n  };\n  \n  return (\n    <div>\n      <button onClick={startRecording}>Start Listening</button>\n      <button onClick={startRecording}>Start Listening</button>\n      <p>{transcript}</p>\n    </div>\n  );\n};\n\nexport default SpeechToText;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAExC,MAAMC,YAAY,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACzB,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGN,QAAQ,CAAC,EAAE,CAAC;EAEhD,MAAMO,cAAc,GAAGA,CAAA,KAAM;IAC3B,MAAMC,WAAW,GAAG,IAAIC,MAAM,CAACC,uBAAuB,CAAC,CAAC;IACxDF,WAAW,CAACG,QAAQ,GAAGC,KAAK,IAAI;MAC9B,MAAMC,YAAY,GAAGD,KAAK,CAACE,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAACT,UAAU;MACnDC,aAAa,CAACO,YAAY,CAAC;IAC7B,CAAC;IACDL,WAAW,CAACO,KAAK,CAAC,CAAC;EACrB,CAAC;EAED,oBACEb,OAAA;IAAAc,QAAA,gBACEd,OAAA;MAAQe,OAAO,EAAEV,cAAe;MAAAS,QAAA,EAAC;IAAe;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eACzDnB,OAAA;MAAQe,OAAO,EAAEV,cAAe;MAAAS,QAAA,EAAC;IAAe;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eACzDnB,OAAA;MAAAc,QAAA,EAAIX;IAAU;MAAAa,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAChB,CAAC;AAEV,CAAC;AAACjB,EAAA,CAnBID,YAAY;AAAAmB,EAAA,GAAZnB,YAAY;AAqBlB,eAAeA,YAAY;AAAC,IAAAmB,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}