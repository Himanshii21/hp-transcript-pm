{"ast":null,"code":"var _jsxFileName = \"/Users/himanshipatel/Documents/react-trans/src/SpeechToText/index.js\",\n  _s = $RefreshSig$();\nimport React, { useState } from \"react\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst SpeechToText = () => {\n  _s();\n  const [transcript, setTranscript] = useState(\"\");\n  const startRecording = () => {\n    const recognition = new window.webkitSpeechRecognition();\n    recognition.onresult = event => {\n      const speechToText = event.results[0][0].transcript;\n      setTranscript(speechToText);\n    };\n    recognition.start();\n  };\n  const stopRecording = () => {};\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: startRecording,\n      children: \"Start Listening\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 18,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: stopRecording,\n      children: \"Start Listening\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 19,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: transcript\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 20,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 17,\n    columnNumber: 5\n  }, this);\n};\n_s(SpeechToText, \"bBAQB9Yehsi1Qhno0JvJVe351zg=\");\n_c = SpeechToText;\nexport default SpeechToText;\nvar _c;\n$RefreshReg$(_c, \"SpeechToText\");","map":{"version":3,"names":["React","useState","jsxDEV","_jsxDEV","SpeechToText","_s","transcript","setTranscript","startRecording","recognition","window","webkitSpeechRecognition","onresult","event","speechToText","results","start","stopRecording","children","onClick","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/himanshipatel/Documents/react-trans/src/SpeechToText/index.js"],"sourcesContent":["import React, { useState } from \"react\";\n\nconst SpeechToText = () => {\n  const [transcript, setTranscript] = useState(\"\");\n\n  const startRecording = () => {\n    const recognition = new window.webkitSpeechRecognition();\n    recognition.onresult = (event) => {\n      const speechToText = event.results[0][0].transcript;\n      setTranscript(speechToText);\n    };\n    recognition.start();\n  };\n  const stopRecording = () => {};\n\n  return (\n    <div>\n      <button onClick={startRecording}>Start Listening</button>\n      <button onClick={stopRecording}>Start Listening</button>\n      <p>{transcript}</p>\n    </div>\n  );\n};\n\nexport default SpeechToText;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAExC,MAAMC,YAAY,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACzB,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGN,QAAQ,CAAC,EAAE,CAAC;EAEhD,MAAMO,cAAc,GAAGA,CAAA,KAAM;IAC3B,MAAMC,WAAW,GAAG,IAAIC,MAAM,CAACC,uBAAuB,CAAC,CAAC;IACxDF,WAAW,CAACG,QAAQ,GAAIC,KAAK,IAAK;MAChC,MAAMC,YAAY,GAAGD,KAAK,CAACE,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAACT,UAAU;MACnDC,aAAa,CAACO,YAAY,CAAC;IAC7B,CAAC;IACDL,WAAW,CAACO,KAAK,CAAC,CAAC;EACrB,CAAC;EACD,MAAMC,aAAa,GAAGA,CAAA,KAAM,CAAC,CAAC;EAE9B,oBACEd,OAAA;IAAAe,QAAA,gBACEf,OAAA;MAAQgB,OAAO,EAAEX,cAAe;MAAAU,QAAA,EAAC;IAAe;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eACzDpB,OAAA;MAAQgB,OAAO,EAAEF,aAAc;MAAAC,QAAA,EAAC;IAAe;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eACxDpB,OAAA;MAAAe,QAAA,EAAIZ;IAAU;MAAAc,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAChB,CAAC;AAEV,CAAC;AAAClB,EAAA,CApBID,YAAY;AAAAoB,EAAA,GAAZpB,YAAY;AAsBlB,eAAeA,YAAY;AAAC,IAAAoB,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}